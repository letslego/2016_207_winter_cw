{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommended Joke Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we'll use some joke rating data to check out recommendating systems, in particular collaborative filtering:\n",
    "\n",
    "Here's a link to the place where I got the data:\n",
    "http://goldberg.berkeley.edu/jester-data/\n",
    "This is an older, smaller dataset, bigger, newer ones are here: http://eigentaste.berkeley.edu/dataset/\n",
    "\n",
    "Get the csv data here:\n",
    "https://drive.google.com/file/d/0B-SYGEBtMGQlaDUyUXlIdl8tYmc/view?usp=sharing\n",
    "\n",
    "Check out some jokes, and get recommended jokes based on your ratings:\n",
    "http://eigentaste.berkeley.edu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering \n",
    "from sklearn.cluster import KMeans \n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD # another approach we are not taking today..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24983, 101)\n",
      "[ 74.    -7.82   8.79  -9.66  -8.16  -7.52  -8.5   -9.85   4.17  -8.98\n",
      "  -4.76  -8.5   -6.75  -7.18   8.45  -7.18  -7.52  -7.43  -9.81  -9.85\n",
      "  -9.85  -9.37   1.5   -4.37  -9.81  -8.5    1.12   7.82   2.86   9.13\n",
      "  -7.43   2.14  -4.08  -9.08   7.82   5.05   4.95  -9.17  -8.4   -8.4   -8.4\n",
      "  -8.11  -9.13  -9.03  -9.08  -7.14  -6.26   3.79  -0.1    3.93   4.13\n",
      "  -8.69  -7.14   3.2    8.3   -4.56   0.92  -9.13  -9.42   2.82  -8.64\n",
      "   8.59   3.59  -6.84  -9.03   2.82  -1.36  -9.08   8.3    5.68  -4.81   0.\n",
      "   0.     0.     0.     0.     0.     0.    -9.42   0.     0.     0.    -7.72\n",
      "   0.     0.     0.     0.     0.     0.     0.     0.     2.82   0.     0.\n",
      "   0.     0.     0.    -5.63   0.     0.     0.  ]\n"
     ]
    }
   ],
   "source": [
    "# import joke data\n",
    "# here's a link to it:\n",
    "# https://drive.google.com/file/d/0B-SYGEBtMGQlaDUyUXlIdl8tYmc/view?usp=sharing\n",
    "\n",
    "ff = \"/Users/dancsi/Downloads/jester-data-1.csv\" # you will need to edit this directory\n",
    "f = open(ff)\n",
    "\n",
    "#column_names = f.readline() # you'd needs this ordinarily\n",
    "\n",
    "data = np.loadtxt(f, delimiter=\",\")\n",
    "\n",
    "# NOTE ABOUT THE DATA STRUCTURE\n",
    "# first column of data: # of jokes rated\n",
    "# columns 2-101 of data: ratings for jokes no. 1 to 100; if rating == 99, no rating is available;\n",
    "\n",
    "# we will re-code the no-rating to 0 for stability of the simple SVD approach we'll take later on\n",
    "\n",
    "# first replace the actual zeroes with small random numbers\n",
    "data[:, 1:][data[:, 1:] == 0] = (np.random.rand(sum(data==0).sum()) * 2.0 - 1.0) * 0.0000001\n",
    "data[:, 1:][data[:, 1:] == 99] = 0\n",
    "\n",
    "print data.shape\n",
    "\n",
    "print data[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Do some EDA on the data\n",
    "\n",
    "How many jokes does an average person rate? What is most jokes rated? What is the fewest number of jokes rated?\n",
    "\n",
    "How many ratings on average does each joke have?\n",
    "\n",
    "What is a joke with the most ratings? Which is one with the fewest ratings?\n",
    "\n",
    "What is the average rating for all jokes? (Be sure to exclude the 99 values!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## fill this in with some code!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unregularized SVD Based Collaborative Filtering\n",
    "\n",
    "## step 1: full SVD\n",
    "\n",
    "We'll do a simple though not very effective way at collaborative filtering: a simple SVD approach.\n",
    "\n",
    "SVD (singular value decomposition) is a way of decomposing a matrix into thing like eigenvectors and eigenvalues. It looks like this for a matrix M:\n",
    "\n",
    "M = U * S * V\n",
    "\n",
    "Here, if we suppose M is an n by p matrix:\n",
    "U is an N by p matrix\n",
    "S is a p by p diagonal matrix\n",
    "V is a p by p matrix\n",
    "\n",
    "In our problem, we have n users rating p jokes\n",
    "\n",
    "In recommender problems, it has the interpretation as follows:\n",
    "U is a representation of the users, as p features\n",
    "V is a representation of the jokes, as p features (different from those in U)\n",
    "S is a vector that gives the joint importance of both feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24983, 100)\n",
      "(100,)\n",
      "(100, 100)\n",
      "[[-7.82  8.79 -9.66 ...,  0.    0.    0.  ]\n",
      " [ 4.08 -0.29  6.36 ...,  0.34 -4.32  1.07]\n",
      " [ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      " ..., \n",
      " [ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      " [ 0.    0.    0.   ...,  0.    0.    0.  ]\n",
      " [ 2.43  2.67 -3.98 ...,  0.    0.    0.  ]]\n",
      "[[ -7.82000000e+00   8.79000000e+00  -9.66000000e+00 ...,   4.31654712e-13\n",
      "    6.03739281e-13   8.28448421e-13]\n",
      " [  4.08000000e+00  -2.90000000e-01   6.36000000e+00 ...,   3.40000000e-01\n",
      "   -4.32000000e+00   1.07000000e+00]\n",
      " [  1.73593778e-14  -1.16504029e-14   1.16989751e-14 ...,   1.09023901e-13\n",
      "   -1.52100554e-13   6.92779167e-13]\n",
      " ..., \n",
      " [ -1.36644168e-14  -1.17995891e-14   8.90780505e-15 ...,   1.13797860e-14\n",
      "   -9.27036226e-15   1.22124533e-15]\n",
      " [ -2.16424101e-14  -5.87377369e-15   7.66400832e-15 ...,  -1.82076576e-14\n",
      "    2.33146835e-15   5.55111512e-16]\n",
      " [  2.43000000e+00   2.67000000e+00  -3.98000000e+00 ...,  -5.99520433e-15\n",
      "   -1.99840144e-15   5.66213743e-15]]\n"
     ]
    }
   ],
   "source": [
    "# the full svd; note the first column is dropped since that has the number of jokes rated, we don't care about that\n",
    "u, s, v = np.linalg.svd(data[:, 1:], full_matrices=False)\n",
    "\n",
    "print u.shape\n",
    "print s.shape\n",
    "print v.shape\n",
    "\n",
    "# these are (nearly) the same, that's the decomposition!\n",
    "print data[:, 1:]\n",
    "print np.dot(np.dot(u, np.diag(s)), v) # the full reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 2: Filling in values by truncating the SVD\n",
    "\n",
    "The SVD above just recovers the original matrix. That is not very interesting, we want to get a new estimate for those missing values. To do this, we need to drop dimensions.\n",
    "\n",
    "Inspect S, you should see that it is sorted in decreasing order. Write code to only take the first few dimensions in each of the projections. This means simply to replace the matrix S (you will have to construct it using np.diag) with a new matrix with many of the diagonal values zeroed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_comp = 10\n",
    "\n",
    "## write some code to take only the first n_comp values in s, then make an approximate reconstruction of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have an approximation to the original matrix. Take the filled in values only and compare them to the non filled in values, do this for a few users and jokes. You might find it useful to write a function to inspect a row or column. Considering doing things like:\n",
    "\n",
    "0. Count how many values are filled in, how many were already present for that row / column\n",
    "1. Compare the range of the filled in values with those not filled in within the row or column\n",
    "2. Compare the mean of the filled in values with those not filled in within the row or column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joke  5  is a great joke\n",
      "user  2  is a funny user\n"
     ]
    }
   ],
   "source": [
    "def inspect_filled_in_joke(ii):\n",
    "    ## code this function to inspect the filled in bits of the approximate SVD\n",
    "    print \"joke \", ii, \" is a great joke\"\n",
    "    \n",
    "def inspect_filled_in_user(ii):\n",
    "    ## code this function to inspect the filled in bits of the approximate SVD\n",
    "    print \"user \", ii, \" is a funny user\"\n",
    "\n",
    "inspect_filled_in_joke(5)\n",
    "inspect_filled_in_user(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Let's actually use this thing. \n",
    "\n",
    "Write a function to recommend a joke (s)he's not rated to a user who has at least one unrated joke. Use it for a few people and print the results.\n",
    "\n",
    "Use it on all users and make a histogram of the recommendations. Compare this to a histogram of missing values. Does this system recommend a joke very often? Does it make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recommend_to_user(ii, verbose = True):\n",
    "    ## recommend a joke to a user\n",
    "    if verbose:\n",
    "        \"Print out the recommendation\"\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "recs = []\n",
    "for user_index in range(0, 25):\n",
    "    recs.append(recommend_to_user(user_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 4: Examining the joke and user spaces\n",
    "\n",
    "The SVD gave us projections of both the users and the jokes. Let's see if those projections give us any insight.\n",
    "\n",
    "Now, plot the first two rows (the projection dimensions appear on the rows here) of the joke projection matrix. Are there different types of jokes?\n",
    "\n",
    "Plot the first two columns (the projection dimensions appear on the columns here) of the user projection matrix. Are there different types of users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## just some scatterplots with plt.scatter(X, Y) should do it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
